"""
–ú–æ–¥—É–ª—å –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from collections import Counter
import json

logger = logging.getLogger(__name__)

class ReasoningEngine:
    """–î–≤–∏–∂–æ–∫ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
    
    def __init__(self, memory_manager=None):
        self.memory = memory_manager
        self.rules = self._load_rules()
        
    async def reason(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è"""
        logger.info("ü§î –ù–∞—á–∏–Ω–∞—é –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è...")
        
        reasoning_result = {
            "input_context": context,
            "conclusions": [],
            "confidence": 0.0,
            "reasoning_steps": [],
            "alternative_explanations": [],
            "timestamp": datetime.now().isoformat(),
            "error": None
        }
        
        try:
            # 1. –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            analysis = await self._analyze_context(context)
            reasoning_result["reasoning_steps"].append(analysis)
            
            # 2. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª
            rule_conclusions = await self._apply_rules(context)
            reasoning_result["conclusions"].extend(rule_conclusions)
            
            # 3. –î–µ–¥—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
            deductive = await self._deductive_reasoning(context)
            reasoning_result["conclusions"].extend(deductive)
            
            # 4. –ò–Ω–¥—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –ø–∞–º—è—Ç—å)
            if self.memory:
                inductive = await self._inductive_reasoning(context)
                reasoning_result["conclusions"].extend(inductive)
            
            # 5. –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            confidence = await self._calculate_confidence(reasoning_result)
            reasoning_result["confidence"] = confidence
            
            # 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
            alternatives = await self._generate_alternatives(reasoning_result)
            reasoning_result["alternative_explanations"] = alternatives
            
            logger.info(f"‚úÖ –†–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}")
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è: {e}"
            logger.error(f"‚ùå {error_msg}")
            reasoning_result["error"] = str(e)
            
        return reasoning_result
        
    async def _analyze_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞"""
        analysis = {
            "step": "context_analysis",
            "user_intent": None,
            "emotional_tone": None,
            "complexity": None,
            "urgency": None,
            "timestamp": datetime.now().isoformat()
        }
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if 'text' in context:
            text = context['text'].lower()
            
            intent_patterns = {
                'question': ['–∫–∞–∫', '—á—Ç–æ', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º'],
                'command': ['—Å–¥–µ–ª–∞–π', '–Ω–∞–π–¥–∏', '–ø–æ–∫–∞–∂–∏', '—Ä–∞—Å—Å–∫–∞–∂–∏', '–≤–∫–ª—é—á–∏', '–≤—ã–∫–ª—é—á–∏'],
                'request': ['–ø–æ–º–æ–≥–∏', '–Ω—É–∂–Ω–æ', '–ø–æ–º–æ—â—å', '–º–æ–∂–µ—à—å'],
                'informational': ['–∑–Ω–∞–µ—à—å', '–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ', '—Ä–∞—Å—Å–∫–∞–∂–∏'],
                'social': ['–ø—Ä–∏–≤–µ—Ç', '–ø–æ–∫–∞', '—Å–ø–∞—Å–∏–±–æ', '–∏–∑–≤–∏–Ω–∏']
            }
            
            for intent, patterns in intent_patterns.items():
                if any(pattern in text for pattern in patterns):
                    analysis['user_intent'] = intent
                    break
                    
        # –û—Ü–µ–Ω–∫–∞ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–æ–Ω–∞
        analysis['emotional_tone'] = await self._detect_emotion(context)
        
        # –û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        if 'text' in context:
            word_count = len(context['text'].split())
            if word_count < 5:
                analysis['complexity'] = 'low'
            elif word_count < 15:
                analysis['complexity'] = 'medium'
            else:
                analysis['complexity'] = 'high'
        else:
            analysis['complexity'] = 'unknown'
                
        # –û—Ü–µ–Ω–∫–∞ —Å—Ä–æ—á–Ω–æ—Å—Ç–∏
        if 'text' in context:
            urgency_words = ['—Å—Ä–æ—á–Ω–æ', '–±—ã—Å—Ç—Ä–æ', '–Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ', '—Å–∫–æ—Ä–µ–µ', '–ø–æ–±—ã—Å—Ç—Ä–µ–µ']
            analysis['urgency'] = 'high' if any(word in context['text'].lower() for word in urgency_words) else 'low'
        else:
            analysis['urgency'] = 'low'
            
        return analysis
        
    async def _apply_rules(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∞–≤–∏–ª"""
        conclusions = []
        
        for rule in self.rules:
            try:
                if await self._rule_matches(rule, context):
                    conclusion = {
                        "type": "rule_based",
                        "rule_id": rule.get("id"),
                        "description": rule.get("description"),
                        "conclusion": rule.get("conclusion"),
                        "confidence": rule.get("confidence", 0.7)
                    }
                    conclusions.append(conclusion)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª–∞ {rule.get('id', 'unknown')}: {e}")
                
        return conclusions
        
    async def _deductive_reasoning(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """–î–µ–¥—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è (–æ—Ç –æ–±—â–µ–≥–æ –∫ —á–∞—Å—Ç–Ω–æ–º—É)"""
        conclusions = []
        
        if 'text' in context:
            text = context['text'].lower()
            
            if '–ø–æ–≥–æ–¥–∞' in text and self._is_morning():
                conclusions.append({
                    "type": "deductive",
                    "premise": "–ó–∞–ø—Ä–æ—Å –æ –ø–æ–≥–æ–¥–µ —É—Ç—Ä–æ–º",
                    "conclusion": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–ª–∞–Ω–∏—Ä—É–µ—Ç —Å–≤–æ–π –¥–µ–Ω—å",
                    "confidence": 0.8
                })
                
            if '–ø–æ–º–æ–≥–∏' in text and '–ø—Ä–æ–±–ª–µ–º' in text:
                conclusions.append({
                    "type": "deductive",
                    "premise": "–ó–∞–ø—Ä–æ—Å –ø–æ–º–æ—â–∏ —Å –ø—Ä–æ–±–ª–µ–º–æ–π",
                    "conclusion": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω—É–∂–¥–∞–µ—Ç—Å—è –≤ —Ä–µ—à–µ–Ω–∏–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏",
                    "confidence": 0.75
                })
                
        return conclusions
        
    async def _inductive_reasoning(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """–ò–Ω–¥—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è (–æ—Ç —á–∞—Å—Ç–Ω–æ–≥–æ –∫ –æ–±—â–µ–º—É)"""
        conclusions = []
        
        if not self.memory:
            return conclusions
            
        try:
            # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
            if hasattr(self.memory, 'find_similar_interactions'):
                similar_interactions = await self.memory.find_similar_interactions(context, limit=5)
            else:
                similar_interactions = []
            
            if similar_interactions:
                common_patterns = self._find_common_patterns(similar_interactions)
                
                for pattern in common_patterns:
                    conclusions.append({
                        "type": "inductive",
                        "pattern": pattern,
                        "conclusion": f"–ù–∞ –æ—Å–Ω–æ–≤–µ {len(similar_interactions)} –ø–æ—Ö–æ–∂–∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π",
                        "confidence": min(0.9, 0.5 + len(similar_interactions) * 0.1)
                    })
                    
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–¥—É–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è: {e}")
                
        return conclusions
        
    async def _calculate_confidence(self, reasoning_result: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –≤—ã–≤–æ–¥–∞—Ö"""
        confidence = 0.5  # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        
        conclusions = reasoning_result.get("conclusions", [])
        if conclusions:
            avg_conclusion_confidence = sum(c.get("confidence", 0.5) for c in conclusions) / len(conclusions)
            confidence = (confidence + avg_conclusion_confidence) / 2
            
        alternatives = reasoning_result.get("alternative_explanations", [])
        if alternatives:
            confidence *= 0.9  # –ù–∞–ª–∏—á–∏–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤ —Å–Ω–∏–∂–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            
        return min(1.0, max(0.0, confidence))
        
    async def _generate_alternatives(self, reasoning_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π"""
        alternatives = []
        context = reasoning_result.get("input_context", {})
        
        if 'text' in context:
            text = context['text'].lower()
            
            if '–ø–æ–≥–æ–¥–∞' in text:
                alternatives.append({
                    "interpretation": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç—Å—è –ø–æ–≥–æ–¥–æ–π –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–µ–∑–¥–∫–∏",
                    "confidence": 0.6
                })
                alternatives.append({
                    "interpretation": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –Ω–∞—á–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä —Å –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–π —Ç–µ–º—ã",
                    "confidence": 0.4
                })
                
            if '–ø–æ–º–æ—â—å' in text or '–ø–æ–º–æ–≥–∏' in text:
                alternatives.append({
                    "interpretation": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å—Ç–æ–ª–∫–Ω—É–ª—Å—è —Å –ø—Ä–æ–±–ª–µ–º–æ–π –∏ –∏—â–µ—Ç —Ä–µ—à–µ–Ω–∏–µ",
                    "confidence": 0.8
                })
                alternatives.append({
                    "interpretation": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞",
                    "confidence": 0.3
                })
                
        return alternatives
        
    def _load_rules(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∞–≤–∏–ª"""
        return [
            {
                "id": "rule_001",
                "description": "–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–¥–æ—Ä–æ–≤–∞–µ—Ç—Å—è, —Ç–æ –Ω—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ–º",
                "condition": "–ø—Ä–∏–≤–µ—Ç",
                "conclusion": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞",
                "confidence": 0.95
            },
            {
                "id": "rule_002",
                "description": "–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç '–∫–∞–∫ –¥–µ–ª–∞', —ç—Ç–æ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–∏—Ç—É–∞–ª",
                "condition": "–∫–∞–∫ –¥–µ–ª–∞",
                "conclusion": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—è–≤–ª—è–µ—Ç –≤–µ–∂–ª–∏–≤–æ—Å—Ç—å, –∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                "confidence": 0.85
            },
            {
                "id": "rule_003",
                "description": "–ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ª–æ–≤–æ '—Å—Ä–æ—á–Ω–æ', —Ç—Ä–µ–±—É–µ—Ç—Å—è –±—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç",
                "condition": "—Å—Ä–æ—á–Ω–æ",
                "conclusion": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏—Å–ø—ã—Ç—ã–≤–∞–µ—Ç —Å—Ä–æ—á–Ω–æ—Å—Ç—å, –Ω—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –±—ã—Å—Ç—Ä–æ",
                "confidence": 0.9
            },
            {
                "id": "rule_004",
                "description": "–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç, –Ω—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –≤–µ–∂–ª–∏–≤–æ—Å—Ç—å—é",
                "condition": "—Å–ø–∞—Å–∏–±–æ",
                "conclusion": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—ë–Ω –æ—Ç–≤–µ—Ç–æ–º",
                "confidence": 0.95
            }
        ]
        
    async def _rule_matches(self, rule: Dict[str, Any], context: Dict[str, Any]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø—Ä–∞–≤–∏–ª–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É"""
        try:
            if 'text' not in context:
                return False
                
            text = context['text'].lower()
            condition = rule.get("condition", "").lower()
            
            return condition in text if condition else False
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–∞–≤–∏–ª–∞: {e}")
            return False
        
    async def _detect_emotion(self, context: Dict[str, Any]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–æ–Ω–∞"""
        if 'text' not in context:
            return 'neutral'
            
        text = context['text'].lower()
        
        positive_words = ['—Å–ø–∞—Å–∏–±–æ', '–æ—Ç–ª–∏—á–Ω–æ', '—Ö–æ—Ä–æ—à–æ', '–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ', '—Ä–∞–¥', '–¥–æ–≤–æ–ª–µ–Ω', '—Å—É–ø–µ—Ä']
        negative_words = ['–ø–ª–æ—Ö–æ', '—É–∂–∞—Å–Ω–æ', '–≥—Ä—É—Å—Ç–Ω–æ', '–∑–ª–æ–π', '—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω', '—Å–µ—Ä–¥–∏—Ç', '–Ω–µ—Ä–≤—ã']
        
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)
        
        if positive_count > negative_count:
            return 'positive'
        elif negative_count > positive_count:
            return 'negative'
        else:
            return 'neutral'
            
    def _is_morning(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —Å–µ–π—á–∞—Å —É—Ç—Ä–æ –∏–ª–∏ –Ω–µ—Ç"""
        hour = datetime.now().hour
        return 6 <= hour < 12
        
    def _find_common_patterns(self, interactions: List[Dict[str, Any]]) -> List[str]:
        """–ü–æ–∏—Å–∫ –æ–±—â–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö"""
        patterns = []
        
        texts = []
        for interaction in interactions:
            if isinstance(interaction, dict):
                if 'text' in interaction:
                    texts.append(interaction['text'].lower())
                elif 'content' in interaction:
                    texts.append(interaction['content'].lower())
                elif 'query' in interaction:
                    texts.append(interaction['query'].lower())
        
        if not texts:
            return patterns
            
        all_words = []
        for text in texts:
            words = text.split()
            all_words.extend([w for w in words if len(w) > 3])
            
        if not all_words:
            return patterns
            
        word_counts = Counter(all_words)
        common_words = [word for word, count in word_counts.most_common(5) if count > 1]
        
        if common_words:
            patterns.append(f"–ß–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–ª–æ–≤–∞: {', '.join(common_words[:3])}")
            
        return patterns
        
    def get_rules_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º"""
        return {
            "total_rules": len(self.rules),
            "rules": [
                {
                    "id": r["id"],
                    "description": r["description"],
                    "confidence": r["confidence"]
                }
                for r in self.rules
            ]
        }