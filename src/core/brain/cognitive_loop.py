"""
–ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π —Ü–∏–∫–ª –∞–≥–µ–Ω—Ç–∞ - –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –º—ã—à–ª–µ–Ω–∏—è
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict, Any, List, Optional
import json
import psutil
import platform

logger = logging.getLogger(__name__)

class CognitiveLoop:
    """–ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
    
    def __init__(self, memory_manager, learning_module=None):
        self.memory = memory_manager
        self.learning = learning_module
        self.thoughts = []
        self.current_context = {}
        
    async def process_input(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π —Ü–∏–∫–ª"""
        logger.info("üß† –ù–∞—á–∞–ª–æ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞")
        
        try:
            # 1. –í–æ—Å–ø—Ä–∏—è—Ç–∏–µ
            perception = await self._perceive(input_data)
            
            # 2. –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            context = await self._analyze_context(perception)
            
            # 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
            relevant_memory = await self._retrieve_memory(perception, context)
            
            # 4. –†–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ
            reasoning = await self._reason(perception, context, relevant_memory)
            
            # 5. –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
            plan = await self._plan_action(reasoning)
            
            # 6. –ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ
            result = await self._execute(plan)
            
            # 7. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–ø—ã—Ç–µ
            if self.learning:
                await self._learn_from_experience(input_data, result)
            
            # 8. –°–∞–º–æ—Ä–µ—Ñ–ª–µ–∫—Å–∏—è
            await self._self_reflect(input_data, result)
            
            logger.info("üß† –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π —Ü–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
        
    async def _perceive(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–æ—Å–ø—Ä–∏—è—Ç–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        perception = {
            "raw_input": input_data,
            "timestamp": datetime.now().isoformat(),
            "input_type": self._detect_input_type(input_data),
            "confidence": 0.9
        }
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É
        if 'text' in input_data:
            perception['sentiment'] = self._analyze_sentiment(input_data['text'])
            perception['text'] = input_data['text']
            
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –∫–æ–º–∞–Ω–¥
        if 'command' in input_data:
            perception['text'] = input_data['command']
            perception['input_type'] = 'command'
            
        return perception
        
    async def _analyze_context(self, perception: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        context = {
            "user_state": await self._get_user_state(),
            "environment_state": await self._get_environment_state(),
            "current_goals": self._get_current_goals()
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è, –µ—Å–ª–∏ –µ—Å—Ç—å –ø–∞–º—è—Ç—å
        if self.memory and hasattr(self.memory, 'get_recent_interactions'):
            try:
                context["previous_interactions"] = await self.memory.get_recent_interactions(limit=5)
            except:
                context["previous_interactions"] = []
        else:
            context["previous_interactions"] = []
            
        return context
        
    async def _retrieve_memory(self, perception: Dict[str, Any], context: Dict[str, Any]) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        if not self.memory:
            return []
            
        query = f"{perception.get('text', '')} {context.get('user_state', {}).get('current_task', '')}"
        
        try:
            relevant_memories = await self.memory.search_memories(
                query=query,
                limit=10,
                threshold=0.3
            )
            return relevant_memories
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–∞–º—è—Ç–∏: {e}")
            return []
        
    async def _reason(self, perception: Dict[str, Any], context: Dict[str, Any], 
                     memories: List[Dict]) -> Dict[str, Any]:
        """–õ–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ"""
        reasoning = {
            "logical_conclusions": await self._make_logical_deductions(perception, memories),
            "emotional_response": self._determine_emotional_response(perception),
            "ethical_considerations": await self._check_ethical_considerations(perception),
            "practical_implications": self._assess_practical_implications(perception)
        }
        return reasoning
        
    async def _plan_action(self, reasoning: Dict[str, Any]) -> Dict[str, Any]:
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π"""
        plan = {
            "primary_action": await self._choose_primary_action(reasoning),
            "fallback_actions": await self._prepare_fallback_actions(reasoning),
            "resources_needed": self._identify_resources_needed(reasoning),
            "estimated_time": self._estimate_execution_time(reasoning),
            "risk_assessment": await self._assess_risks(reasoning)
        }
        return plan
        
    async def _execute(self, plan: Dict[str, Any]) -> Dict[str, Any]:
        """–ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–ª–∞–Ω–∞"""
        result = {
            "success": True,
            "execution_start": datetime.now().isoformat(),
            "actions_taken": [],
            "results": {},
            "errors": [],
            "execution_end": None
        }
        
        try:
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è
            action_result = await self._perform_action(plan['primary_action'])
            result['actions_taken'].append(plan['primary_action']['action'])
            result['results']['primary'] = action_result
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if not action_result.get('success', False):
                # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
                for fallback in plan['fallback_actions']:
                    fallback_result = await self._perform_action(fallback)
                    result['actions_taken'].append(fallback['action'])
                    result['results'][f'fallback_{fallback["type"]}'] = fallback_result
                    
                    if fallback_result.get('success', False):
                        break
                        
        except Exception as e:
            result['success'] = False
            result['errors'].append(str(e))
            logger.error(f"–û—à–∏–±–∫–∞ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
            
        result['execution_end'] = datetime.now().isoformat()
        return result
        
    async def _learn_from_experience(self, input_data: Dict[str, Any], result: Dict[str, Any]):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—ã—Ç–∞"""
        if not self.learning:
            return
            
        learning_data = {
            "input": input_data,
            "output": result,
            "success_rate": self._calculate_success_rate(result),
            "improvement_areas": await self._identify_improvement_areas(result),
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            if hasattr(self.learning, 'store_experience'):
                await self.learning.store_experience(learning_data)
            
            # –ê–Ω–∞–ª–∏–∑ –¥–ª—è —Å–∞–º–æ—É–ª—É—á—à–µ–Ω–∏—è
            if learning_data['success_rate'] < 0.7 and hasattr(self.learning, 'improve_in_area'):
                await self._initiate_self_improvement(learning_data)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ–ø—ã—Ç–µ: {e}")
            
    async def _self_reflect(self, input_data: Dict[str, Any], result: Dict[str, Any]):
        """–°–∞–º–æ—Ä–µ—Ñ–ª–µ–∫—Å–∏—è –∏ —Å–∞–º–æ–∫—Ä–∏—Ç–∏–∫–∞"""
        reflection = {
            "effectiveness": self._assess_effectiveness(result),
            "mistakes_made": await self._identify_mistakes(input_data, result),
            "lessons_learned": await self._extract_lessons(input_data, result),
            "personal_growth": self._assess_personal_growth(),
            "future_improvements": await self._plan_future_improvements(),
            "timestamp": datetime.now().isoformat()
        }
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ –≤ –ø–∞–º—è—Ç—å
        if self.memory and hasattr(self.memory, 'store_reflection'):
            try:
                await self.memory.store_reflection(reflection)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏: {e}")
        
        # –ê–Ω–∞–ª–∏–∑ –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è
        if reflection['effectiveness'] < 0.8:
            logger.warning("‚ö†Ô∏è –ù–∏–∑–∫–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, —Ç—Ä–µ–±—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏–µ")
            self._adjust_cognitive_parameters()
            
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    
    def _detect_input_type(self, input_data: Dict[str, Any]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if 'text' in input_data:
            return 'text'
        elif 'command' in input_data:
            return 'command'
        elif 'audio' in input_data:
            return 'audio'
        elif 'image' in input_data:
            return 'image'
        else:
            return 'unknown'
            
    async def _get_user_state(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        return {
            "mood": "neutral",
            "attention_level": "high",
            "current_task": "unknown",
            "location": "desktop"
        }
        
    async def _get_environment_state(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        try:
            return {
                "system": platform.system(),
                "cpu_usage": psutil.cpu_percent(interval=0.1),
                "memory_usage": psutil.virtual_memory().percent,
                "disk_usage": psutil.disk_usage('/').percent,
                "time_of_day": datetime.now().strftime("%H:%M"),
                "day_of_week": datetime.now().strftime("%A")
            }
        except:
            return {
                "system": "unknown",
                "cpu_usage": 0,
                "memory_usage": 0,
                "disk_usage": 0,
                "time_of_day": datetime.now().strftime("%H:%M"),
                "day_of_week": datetime.now().strftime("%A")
            }
        
    def _get_current_goals(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö —Ü–µ–ª–µ–π"""
        return [
            "–ü–æ–º–æ—á—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é",
            "–°–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–µ",
            "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤"
        ]
        
    async def _make_logical_deductions(self, perception: Dict[str, Any], memories: List[Dict]) -> List[str]:
        """–õ–æ–≥–∏—á–µ—Å–∫–∏–µ –¥–µ–¥—É–∫—Ü–∏–∏"""
        deductions = []
        
        text = perception.get('text', '').lower()
        
        if '–æ—Ç–∫—Ä–æ–π' in text:
            deductions.append("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –æ—Ç–∫—Ä—ã—Ç—å —á—Ç–æ-—Ç–æ")
        if '–ø–æ–º–æ–≥–∏' in text:
            deductions.append("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –ø–æ–º–æ—â–∏")
        if '–Ω–∞–π–¥–∏' in text:
            deductions.append("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é")
                
        return deductions
        
    def _determine_emotional_response(self, perception: Dict[str, Any]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        sentiment = perception.get('sentiment', 'neutral')
        
        emotional_responses = {
            'positive': '—Ä–∞–¥–æ—Å—Ç–Ω—ã–π',
            'neutral': '—Å–ø–æ–∫–æ–π–Ω—ã–π',
            'negative': '—Å–æ—á—É–≤—Å—Ç–≤—É—é—â–∏–π',
            'urgent': '–≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã–π'
        }
        
        return emotional_responses.get(sentiment, '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π')
        
    async def _check_ethical_considerations(self, perception: Dict[str, Any]) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —ç—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        considerations = []
        text = perception.get('text', '').lower()
        
        unethical_keywords = ['–≤–∑–ª–æ–º–∞—Ç—å', '—É–∫—Ä–∞—Å—Ç—å', '–æ–±–º–∞–Ω—É—Ç—å', '–Ω–∞–≤—Ä–µ–¥–∏—Ç—å']
        
        for keyword in unethical_keywords:
            if keyword in text:
                considerations.append(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–µ—ç—Ç–∏—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {keyword}")
                
        return considerations
        
    def _assess_practical_implications(self, perception: Dict[str, Any]) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–π"""
        implications = {
            "complexity": "low",
            "time_required": "short",
            "resources_needed": [],
            "dependencies": [],
            "potential_risks": []
        }
        
        text_length = len(perception.get('text', ''))
        if text_length > 50:
            implications['complexity'] = 'medium'
            implications['time_required'] = 'medium'
        if text_length > 200:
            implications['complexity'] = 'high'
            implications['time_required'] = 'long'
            
        return implications
        
    async def _choose_primary_action(self, reasoning: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã–±–æ—Ä –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è"""
        if reasoning.get('ethical_considerations'):
            return {
                "type": "ethical_response",
                "action": "explain_ethics",
                "priority": "high"
            }
            
        return {
            "type": "standard_response",
            "action": "process_query",
            "priority": "normal"
        }
        
    async def _prepare_fallback_actions(self, reasoning: Dict[str, Any]) -> List[Dict[str, Any]]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π"""
        return [
            {
                "type": "simplified_response",
                "action": "give_simple_answer",
                "priority": "medium"
            },
            {
                "type": "deferred_action",
                "action": "schedule_for_later",
                "priority": "low"
            }
        ]
        
    def _identify_resources_needed(self, reasoning: Dict[str, Any]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤"""
        resources = ["–ø–∞–º—è—Ç—å", "–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω–æ–µ –≤—Ä–µ–º—è"]
        
        if reasoning.get('practical_implications', {}).get('complexity') == 'high':
            resources.append("–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è")
            
        return resources
        
    def _estimate_execution_time(self, reasoning: Dict[str, Any]) -> str:
        """–û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è"""
        complexity = reasoning.get('practical_implications', {}).get('complexity', 'low')
        
        time_estimates = {
            'low': '–º–µ–Ω–µ–µ 1 —Å–µ–∫—É–Ω–¥—ã',
            'medium': '1-3 —Å–µ–∫—É–Ω–¥—ã',
            'high': '3-10 —Å–µ–∫—É–Ω–¥'
        }
        
        return time_estimates.get(complexity, '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        
    async def _assess_risks(self, reasoning: Dict[str, Any]) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤"""
        risks = {
            "incorrect_response": "—Å—Ä–µ–¥–Ω–∏–π",
            "user_dissatisfaction": "—Å—Ä–µ–¥–Ω–∏–π"
        }
        
        if reasoning.get('ethical_considerations'):
            risks['privacy_violation'] = '–≤—ã—Å–æ–∫–∏–π'
            
        return risks
        
    async def _perform_action(self, action: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è"""
        return {
            "success": True,
            "action_type": action["type"],
            "result": f"–í—ã–ø–æ–ª–Ω–µ–Ω–æ –¥–µ–π—Å—Ç–≤–∏–µ: {action['action']}",
            "timestamp": datetime.now().isoformat()
        }
        
    def _calculate_success_rate(self, result: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ —É—Å–ø–µ—Ö–∞"""
        if result.get('success', False) and not result.get('errors'):
            return 1.0
        return 0.5
        
    async def _identify_improvement_areas(self, result: Dict[str, Any]) -> List[str]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–±–ª–∞—Å—Ç–µ–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è"""
        improvements = []
        
        if result.get('errors'):
            improvements.append("–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫")
            
        execution_time = self._calculate_execution_time(result)
        if execution_time > 5:
            improvements.append("–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
            
        return improvements
        
    async def _initiate_self_improvement(self, learning_data: Dict[str, Any]):
        """–ò–Ω–∏—Ü–∏–∞—Ü–∏—è —Å–∞–º–æ—É–ª—É—á—à–µ–Ω–∏—è"""
        logger.info("üöÄ –ò–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∞–º–æ—É–ª—É—á—à–µ–Ω–∏—è")
        
        improvements = learning_data.get('improvement_areas', [])
        
        for area in improvements:
            logger.info(f"üìà –£–ª—É—á—à–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏: {area}")
            if self.learning and hasattr(self.learning, 'improve_in_area'):
                await self.learning.improve_in_area(area)
            
    def _assess_effectiveness(self, result: Dict[str, Any]) -> float:
        """–û—Ü–µ–Ω–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        effectiveness = 1.0
        
        if result.get('errors'):
            effectiveness *= 0.8
            
        if self._calculate_execution_time(result) > 10:
            effectiveness *= 0.9
            
        return effectiveness
        
    async def _identify_mistakes(self, input_data: Dict[str, Any], result: Dict[str, Any]) -> List[str]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—à–∏–±–æ–∫"""
        mistakes = []
        
        for error in result.get('errors', []):
            mistakes.append(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {error}")
            
        if not result.get('success', True):
            mistakes.append("–ù–µ—É–¥–∞—á–Ω—ã–π –≤—ã–±–æ—Ä –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è")
            
        return mistakes
        
    async def _extract_lessons(self, input_data: Dict[str, Any], result: Dict[str, Any]) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É—Ä–æ–∫–æ–≤"""
        lessons = []
        
        if result.get('errors'):
            lessons.append("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–ª—É—á—à–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –∏—Å–∫–ª—é—á–µ–Ω–∏–π")
            
        if self._calculate_execution_time(result) > 5:
            lessons.append("–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
            
        return lessons
        
    def _assess_personal_growth(self) -> float:
        """–û—Ü–µ–Ω–∫–∞ –ª–∏—á–Ω–æ—Å—Ç–Ω–æ–≥–æ —Ä–æ—Å—Ç–∞"""
        return 0.75
        
    async def _plan_future_improvements(self) -> List[Dict[str, Any]]:
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±—É–¥—É—â–∏—Ö —É–ª—É—á—à–µ–Ω–∏–π"""
        return [
            {
                "area": "—Å–∫–æ—Ä–æ—Å—Ç—å_–æ—Ç–≤–µ—Ç–∞",
                "goal": "—É–º–µ–Ω—å—à–∏—Ç—å –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ 20%",
                "timeline": "2 –Ω–µ–¥–µ–ª–∏"
            },
            {
                "area": "—Ç–æ—á–Ω–æ—Å—Ç—å_–∞–Ω–∞–ª–∏–∑–∞",
                "goal": "—É–≤–µ–ª–∏—á–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –¥–æ 95%",
                "timeline": "1 –º–µ—Å—è—Ü"
            }
        ]
        
    def _calculate_execution_time(self, result: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        try:
            start = datetime.fromisoformat(result.get('execution_start', datetime.now().isoformat()))
            end = datetime.fromisoformat(result.get('execution_end', datetime.now().isoformat()))
            return (end - start).total_seconds()
        except:
            return 0.0
        
    def _adjust_cognitive_parameters(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        logger.info("‚öôÔ∏è –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        
    def _analyze_sentiment(self, text: str) -> str:
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞"""
        positive_words = ['—Å–ø–∞—Å–∏–±–æ', '–æ—Ç–ª–∏—á–Ω–æ', '—Ö–æ—Ä–æ—à–æ', '–ø–æ–º–æ–≥–∏']
        negative_words = ['–ø–ª–æ—Ö–æ', '–æ—à–∏–±–∫–∞', '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ']
        
        text_lower = text.lower()
        
        if any(word in text_lower for word in positive_words):
            return 'positive'
        elif any(word in text_lower for word in negative_words):
            return 'negative'
        elif '—Å—Ä–æ—á–Ω–æ' in text_lower or '–±—ã—Å—Ç—Ä–æ' in text_lower:
            return 'urgent'
        else:
            return 'neutral'