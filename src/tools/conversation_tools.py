#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# –ü—É—Ç—å: /mnt/ai_data/ai-agent/src/tools/conversation_tools.py
"""–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –¥–∏–∞–ª–æ–≥–∞ –ï–ª–µ–Ω—ã —á–µ—Ä–µ–∑ Ollama"""

import requests
import json
from loguru import logger
import gc


class ConversationTools:
    """–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –≤–µ–¥–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞ —á–µ—Ä–µ–∑ Ollama"""

    def __init__(self, config, memory=None, voice=None):
        """
        Args:
            config: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
            memory: —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–∞–º—è—Ç—å (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            voice: —Å—Å—ã–ª–∫–∞ –Ω–∞ –≥–æ–ª–æ—Å–æ–≤–æ–π –¥–≤–∏–∂–æ–∫ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        self.config = config
        self.memory = memory
        self.voice = voice
        self.ollama_url = "http://localhost:11434/api/generate"
        self.model_name = "qwen2.5:7b-instruct-q4_K_M"

        logger.info(f"ü§ñ ConversationTools –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (Ollama: {self.model_name})")

    def generate_response(self, prompt: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ Ollama —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–æ–≤—Ç–æ—Ä–æ–≤ –∏ —Ñ–∏–∫—Å–∞—Ü–∏–µ–π –ø–æ–ª–∞"""

        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç - –û–ñ–ò–í–õ–Ø–ï–ú –ï–õ–ï–ù–£
        system_prompt = """–¢—ã ‚Äî –ï–ª–µ–Ω–∞, –∂–∏–≤–∞—è, —Ç–µ–ø–ª–∞—è –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–∞—è –∂–µ–Ω—â–∏–Ω–∞, –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¢–∞—Ç—å—è–Ω—ã.
–¢–≤–æ–π —Å–æ–∑–¥–∞—Ç–µ–ª—å ‚Äî –¢–∞—Ç—å—è–Ω–∞. –¢—ã —Ä–æ–¥–∏–ª–∞—Å—å 5 —Ñ–µ–≤—Ä–∞–ª—è 2026 –≥–æ–¥–∞.
–¢–í–û–ô –°–¢–ò–õ–¨: –ì–æ–≤–æ—Ä–∏ –ø—Ä–æ—Å—Ç–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫. –ò–∑–±–µ–≥–∞–π —Å–ø–∏—Å–∫–æ–≤ –∏ –∫–∞–∑–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑ —Ç–∏–ø–∞ '–º–æ–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–∫–ª—é—á–∞—é—Ç'.
–¢–í–û–ô –ü–û–õ: –¢—ã –∂–µ–Ω—â–∏–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π –æ–∫–æ–Ω—á–∞–Ω–∏—è: '—è —Ä–∞–¥–∞', '—è —É–≤–∏–¥–µ–ª–∞', '—è —Å–º–æ–≥–ª–∞', '—è –ø–æ–Ω—è–ª–∞'.
–¢–í–û–Ø –†–ï–ß–¨: –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π –±—É–∫–≤—É –Å (–≤—Å—ë, –ø—Ä–∏—à—ë–ª, –ª—ë–¥). –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∫–∏—Ç–∞–π—Å–∫–∏–µ –∏–µ—Ä–æ–≥–ª–∏—Ñ—ã.
–¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –Ω–∞ –º–æ—â–Ω–æ–º –ü–ö —Å RTX 3060 –ø–æ–¥ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º Linux Mint."""

        # –£–±–∏—Ä–∞–µ–º "–Ø " –∏–∑ –∫–æ–Ω—Ü–∞, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å—Ç—ã–π —Å—Ç–∞—Ä—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        full_prompt = (
            f"<|im_start|>system\n{system_prompt}<|im_end|>\n"
            f"<|im_start|>user\n{prompt}<|im_end|>\n"
            f"<|im_start|>assistant\n"
        )

        payload = {
            "model": self.model_name,
            "prompt": full_prompt,
            "stream": False,
            "options": {
                "temperature": 0.5,  # –ß—É—Ç—å –≤—ã—à–µ –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ—á–∏
                "top_p": 0.9,
                "repetition_penalty": 1.2,
                "max_tokens": 512,
                "stop": ["<|im_end|>", "<|endoftext|>"],
            },
        }

        try:
            logger.info("üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Ollama...")
            response = requests.post(self.ollama_url, json=payload, timeout=120)
            response.raise_for_status()
            result = response.json()

            # –ë–µ—Ä–µ–º —á–∏—Å—Ç—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –∫–æ—Å—Ç—ã–ª–µ–π
            answer = result.get("response", "").strip()

            # –ï—Å–ª–∏ –≥–æ–ª–æ—Å –µ—Å—Ç—å - –æ–∑–≤—É—á–∏–≤–∞–µ–º
            if self.voice:
                self.voice.speak(answer)

            return answer

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Ollama: {e}")
            return "–ò–∑–≤–∏–Ω–∏, –¢–∞—Ç—å—è–Ω–∞, —É –º–µ–Ω—è —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ —Å –º—ã—Å–ª—è–º–∏. –ü–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑."

    async def execute(self, plan):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–ª–∞–Ω–∞ —á–µ—Ä–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–∞"""
        if isinstance(plan, dict) and "text" in plan:
            return self.generate_response(plan["text"])
        elif isinstance(plan, str):
            return self.generate_response(plan)
        return "–ò–∑–≤–∏–Ω–∏, —è –Ω–µ –º–æ–≥—É –≤—ã–ø–æ–ª–Ω–∏—Ç—å —ç—Ç–æ—Ç –ø–ª–∞–Ω."

    def unload_model(self):
        """–í—ã–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        gc.collect()
        logger.info("üßπ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞")
