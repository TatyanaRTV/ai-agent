"""
–î–≤–∏–∂–æ–∫ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–∫—Ä–∞–Ω–∞
"""

import logging
from PIL import Image
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import mss
import numpy as np

logger = logging.getLogger(__name__)

class VisionEngine:
    """–î–≤–∏–∂–æ–∫ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è"""
    
    def __init__(self, model_name="vikhyatk/moondream2"):
        self.model_name = model_name
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        logger.info(f"üëÅÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∑—Ä–µ–Ω–∏—è: {model_name}")
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                trust_remote_code=True,
                torch_dtype=torch.float16
            ).to(self.device)
            self.model.eval()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –∑—Ä–µ–Ω–∏—è: {e}")
            raise
            
    def capture_screen(self):
        """–ó–∞—Ö–≤–∞—Ç —Ç–µ–∫—É—â–µ–≥–æ —ç–∫—Ä–∞–Ω–∞"""
        with mss.mss() as sct:
            monitor = sct.monitors[1]
            screenshot = sct.grab(monitor)
            img = Image.frombytes("RGB", screenshot.size, screenshot.rgb)
            return img
            
    def analyze_screen(self, question="–ß—Ç–æ —Ç—ã –≤–∏–¥–∏—à—å –Ω–∞ —ç–∫—Ä–∞–Ω–µ?"):
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —ç–∫—Ä–∞–Ω–∞"""
        try:
            # –ó–∞—Ö–≤–∞—Ç —ç–∫—Ä–∞–Ω–∞
            image = self.capture_screen()
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            enc_image = self.model.encode_image(image)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            answer = self.model.answer_question(
                enc_image,
                question,
                self.tokenizer
            )
            
            return {
                "analysis": answer,
                "image_size": image.size,
                "timestamp": torch.cuda.get_device_properties(0).total_memory if torch.cuda.is_available() else None
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —ç–∫—Ä–∞–Ω–∞: {e}")
            return {"error": str(e)}
            
    def analyze_image(self, image_path, question=None):
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            image = Image.open(image_path).convert("RGB")
            
            if question is None:
                question = "–û–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–æ, —á—Ç–æ —Ç—ã –≤–∏–¥–∏—à—å –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏?"
                
            enc_image = self.model.encode_image(image)
            answer = self.model.answer_question(enc_image, question, self.tokenizer)
            
            return {
                "description": answer,
                "image_path": image_path,
                "dimensions": image.size
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {e}")
            return {"error": str(e)}