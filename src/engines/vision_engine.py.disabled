"""
–î–≤–∏–∂–æ–∫ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–∫—Ä–∞–Ω–∞
"""

import logging
from PIL import Image
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import mss
import numpy as np

logger = logging.getLogger(__name__)

class VisionEngine:
    """–î–≤–∏–∂–æ–∫ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è"""
    
    def __init__(self, model_name="vikhyatk/moondream2"):
        self.model_name = model_name
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        logger.info(f"üëÅÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∑—Ä–µ–Ω–∏—è: {model_name}")
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name, 
                trust_remote_code=True
            )
            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                trust_remote_code=True
                # torch_dtype –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á—ë–Ω
            ).to(self.device)
            
            # ‚úÖ –§–ò–ö–° –î–õ–Ø –ù–û–í–û–ô –í–ï–†–°–ò–ò TRANSFORMERS
            if not hasattr(self.model, 'all_tied_weights_keys'):
                self.model.all_tied_weights_keys = []
                
            self.model.eval()
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑—Ä–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –∑—Ä–µ–Ω–∏—è: {e}")
            raise
            
    def capture_screen(self):
        """–ó–∞—Ö–≤–∞—Ç —Ç–µ–∫—É—â–µ–≥–æ —ç–∫—Ä–∞–Ω–∞"""
        with mss.mss() as sct:
            monitor = sct.monitors[1]
            screenshot = sct.grab(monitor)
            img = Image.frombytes("RGB", screenshot.size, screenshot.rgb)
            return img
            
    def analyze_screen(self, question="–ß—Ç–æ —Ç—ã –≤–∏–¥–∏—à—å –Ω–∞ —ç–∫—Ä–∞–Ω–µ?"):
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —ç–∫—Ä–∞–Ω–∞"""
        try:
            image = self.capture_screen()
            enc_image = self.model.encode_image(image)
            answer = self.model.answer_question(enc_image, question, self.tokenizer)
            
            return {
                "analysis": answer,
                "image_size": image.size,
                "timestamp": torch.cuda.get_device_properties(0).total_memory if torch.cuda.is_available() else None
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —ç–∫—Ä–∞–Ω–∞: {e}")
            return {"error": str(e)}
            
    def analyze_image(self, image_path, question=None):
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            image = Image.open(image_path).convert("RGB")
            
            if question is None:
                question = "–û–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–æ, —á—Ç–æ —Ç—ã –≤–∏–¥–∏—à—å –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏?"
                
            enc_image = self.model.encode_image(image)
            answer = self.model.answer_question(enc_image, question, self.tokenizer)
            
            return {
                "description": answer,
                "image_path": image_path,
                "dimensions": image.size
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {e}")
            return {"error": str(e)}